import pandas as pd
import re
from html import unescape
from html.parser import HTMLParser

print("="*80)
print("DAY 4: TEXT CLEANING & SEO TITLE GENERATION")
print("="*80)

# HTML tag stripper class
class MLStripper(HTMLParser):
    def __init__(self):
        super().__init__()
        self.reset()
        self.strict = False
        self.convert_charrefs= True
        self.text = []
    def handle_data(self, d):
        self.text.append(d)
    def get_data(self):
        return ''.join(self.text)

def strip_html_tags(html):
    """Remove HTML tags and return plain text"""
    if pd.isna(html):
        return ""
    s = MLStripper()
    s.feed(str(html))
    return s.get_data().strip()

# ==============================================================================
# 1. LOAD DATA
# ==============================================================================
print("\n[STEP 1] Loading data from Day 3...")
df = pd.read_csv('../data/shopify_clean_step3.csv')
print(f"âœ… Loaded {len(df):,} products with {len(df.columns)} columns")
print(f"âœ… Preserved Day 3 calculated columns: price_valid, discount_valid, profit_margin, etc.")

# ==============================================================================
# 2. VENDOR STANDARDIZATION
# ==============================================================================
print("\n" + "="*80)
print("[STEP 2] VENDOR STANDARDIZATION")
print("="*80)

print(f"\nBefore cleaning:")
print(f"  - Unique vendors: {df['Vendor'].nunique()}")
print(f"  - Missing vendors: {df['Vendor'].isna().sum()}")

# Show sample of current vendor names
print(f"\nSample vendor names (before):")
print(df['Vendor'].value_counts().head(5))

# Clean vendor names
df['Vendor'] = df['Vendor'].str.strip()  # Remove whitespace
df['Vendor'] = df['Vendor'].str.title()  # Convert to Title Case
df['Vendor'] = df['Vendor'].fillna('Unknown Vendor')  # Fill missing

print(f"\nAfter cleaning:")
print(f"  - Unique vendors: {df['Vendor'].nunique()}")
print(f"  - Missing vendors: {df['Vendor'].isna().sum()}")

print(f"\nSample vendor names (after):")
print(df['Vendor'].value_counts().head(5))

# ==============================================================================
# 3. CATEGORY CLEANING
# ==============================================================================
print("\n" + "="*80)
print("[STEP 3] CATEGORY CLEANING")
print("="*80)

print(f"\nBefore cleaning:")
print(f"  - Unique categories: {df['Product Category'].nunique()}")
print(f"  - Missing categories: {df['Product Category'].isna().sum()}")

# Clean categories
df['Product Category'] = df['Product Category'].str.strip()
df['Product Category'] = df['Product Category'].str.title()
df['Product Category'] = df['Product Category'].fillna('Uncategorized')

print(f"\nAfter cleaning:")
print(f"  - Unique categories: {df['Product Category'].nunique()}")
print(f"  - Missing categories: {df['Product Category'].isna().sum()}")

print(f"\nTop 5 categories (after):")
print(df['Product Category'].value_counts().head(5))

# ==============================================================================
# 4. TITLE CLEANING
# ==============================================================================
print("\n" + "="*80)
print("[STEP 4] TITLE CLEANING")
print("="*80)

# Clean titles
df['Title'] = df['Title'].str.strip()
df['Title'] = df['Title'].apply(lambda x: re.sub(r'\s+', ' ', str(x)) if pd.notna(x) else x)  # Remove extra spaces
df['Title'] = df['Title'].apply(lambda x: re.sub(r'[^\w\s\-,&().]', '', str(x)) if pd.notna(x) else x)  # Remove special chars but keep common ones

# Calculate title length
df['title_length'] = df['Title'].str.len()

print(f"\nTitle statistics:")
print(f"  - Average length: {df['title_length'].mean():.0f} characters")
print(f"  - Max length: {df['title_length'].max():.0f} characters")
print(f"  - Titles over 70 chars: {(df['title_length'] > 70).sum():,} ({(df['title_length'] > 70).sum()/len(df)*100:.2f}%)")

# Create truncated version for long titles
df['title_truncated'] = df['Title'].apply(lambda x: x[:67] + '...' if len(str(x)) > 70 else x)

# ==============================================================================
# 5. SEO TITLE GENERATION (THE BIG ONE!)
# ==============================================================================
print("\n" + "="*80)
print("[STEP 5] SEO TITLE GENERATION ðŸš€")
print("="*80)

print(f"\nBefore generation:")
seo_before = df['SEO Title'].notna().sum()
print(f"  - Products with SEO Title: {seo_before:,} ({seo_before/len(df)*100:.2f}%)")

def generate_seo_title(row):
    """Generate optimized SEO title"""
    title = str(row['Title'])[:50]  # Limit base title
    vendor = str(row['Vendor'])
    category = str(row['Product Category'])
    
    # Try full format first
    full_format = f"{title} - {vendor} | Premium {category}"
    
    # If too long, use shorter format
    if len(full_format) > 60:
        short_format = f"{title} - {vendor}"
        if len(short_format) > 60:
            # Even shorter - just optimized title
            return title[:60]
        return short_format
    
    return full_format

# Generate SEO titles for ALL products
print("\nâ³ Generating 5,869 SEO titles...")
df['SEO Title'] = df.apply(generate_seo_title, axis=1)

print(f"\nAfter generation:")
seo_after = df['SEO Title'].notna().sum()
print(f"  - Products with SEO Title: {seo_after:,} ({seo_after/len(df)*100:.2f}%)")
print(f"  - âœ… Generated {seo_after - seo_before:,} new SEO titles!")

print(f"\nðŸ“‹ Sample of generated SEO titles:")
for i, title in enumerate(df['SEO Title'].head(10), 1):
    print(f"  {i}. {title}")

# ==============================================================================
# 6. SEO DESCRIPTION GENERATION
# ==============================================================================
print("\n" + "="*80)
print("[STEP 6] SEO DESCRIPTION GENERATION")
print("="*80)

print(f"\nBefore generation:")
desc_before = df['SEO Description'].notna().sum()
print(f"  - Products with SEO Description: {desc_before:,} ({desc_before/len(df)*100:.2f}%)")

def generate_seo_description(row):
    """Generate SEO meta description"""
    if pd.notna(row['SEO Description']) and str(row['SEO Description']).strip():
        return row['SEO Description']
    
    title = str(row['Title'])
    vendor = str(row['Vendor'])
    
    # Try to extract from Body HTML
    body_text = strip_html_tags(row['Body (HTML)'])
    
    if body_text and len(body_text) > 20:
        # Use body content
        desc = f"Shop {title} from {vendor}. {body_text}"
    else:
        # Fallback to title-based description
        category = str(row['Product Category'])
        desc = f"Shop {title} from {vendor}. Premium {category} with free shipping available."
    
    # Trim to 155 characters (SEO limit)
    if len(desc) > 155:
        desc = desc[:152] + "..."
    
    return desc

print("\nâ³ Generating SEO descriptions...")
df['SEO Description'] = df.apply(generate_seo_description, axis=1)

print(f"\nAfter generation:")
desc_after = df['SEO Description'].notna().sum()
print(f"  - Products with SEO Description: {desc_after:,} ({desc_after/len(df)*100:.2f}%)")
print(f"  - âœ… Generated {desc_after - desc_before:,} new SEO descriptions!")

# ==============================================================================
# 7. TAGS CLEANING
# ==============================================================================
print("\n" + "="*80)
print("[STEP 7] TAGS CLEANING")
print("="*80)

print(f"\nBefore cleaning:")
tags_before = df['Tags'].isna().sum()
print(f"  - Products missing tags: {tags_before:,} ({tags_before/len(df)*100:.2f}%)")

# Clean tags
df['Tags'] = df['Tags'].fillna('untagged')
df['Tags'] = df['Tags'].str.lower()
df['Tags'] = df['Tags'].str.strip()

# Count tags per product
df['tag_count'] = df['Tags'].apply(lambda x: len(str(x).split(',')) if x != 'untagged' else 0)

print(f"\nAfter cleaning:")
print(f"  - Products with 'untagged': {(df['Tags'] == 'untagged').sum():,}")
print(f"  - Average tags per product: {df['tag_count'].mean():.1f}")
print(f"  - Max tags on a product: {df['tag_count'].max()}")

# ==============================================================================
# 8. BODY (HTML) CLEANING
# ==============================================================================
print("\n" + "="*80)
print("[STEP 8] BODY/DESCRIPTION ANALYSIS")
print("="*80)

# Calculate description length
df['description_length'] = df['Body (HTML)'].apply(lambda x: len(strip_html_tags(x)) if pd.notna(x) else 0)

missing_body = (df['description_length'] == 0).sum()
print(f"\nProducts missing description: {missing_body:,} ({missing_body/len(df)*100:.2f}%)")
print(f"Average description length: {df['description_length'].mean():.0f} characters")

# ==============================================================================
# 9. CREATE QUALITY FLAGS
# ==============================================================================
print("\n" + "="*80)
print("[STEP 9] CREATING QUALITY FLAGS")
print("="*80)

# Create quality flags
df['has_seo_title'] = df['SEO Title'].notna() & (df['SEO Title'] != '')
df['has_seo_description'] = df['SEO Description'].notna() & (df['SEO Description'] != '')
df['has_tags'] = df['Tags'] != 'untagged'
df['has_description'] = df['description_length'] > 0

# Calculate content quality score (0-100)
def calculate_quality_score(row):
    score = 0
    
    # SEO Title (25 points)
    if row['has_seo_title']:
        score += 25
    
    # SEO Description (25 points)
    if row['has_seo_description']:
        score += 25
    
    # Tags (20 points)
    if row['has_tags']:
        score += 20
    
    # Description (20 points)
    if row['has_description']:
        score += 20
    
    # Title length optimization (10 points)
    if 30 <= row['title_length'] <= 70:
        score += 10
    
    return score

df['content_quality_score'] = df.apply(calculate_quality_score, axis=1)

print(f"\nQuality Flags:")
print(f"  - has_seo_title: {df['has_seo_title'].sum():,} ({df['has_seo_title'].sum()/len(df)*100:.2f}%)")
print(f"  - has_seo_description: {df['has_seo_description'].sum():,} ({df['has_seo_description'].sum()/len(df)*100:.2f}%)")
print(f"  - has_tags: {df['has_tags'].sum():,} ({df['has_tags'].sum()/len(df)*100:.2f}%)")
print(f"  - has_description: {df['has_description'].sum():,} ({df['has_description'].sum()/len(df)*100:.2f}%)")

print(f"\nContent Quality Score Distribution:")
print(f"  - Average score: {df['content_quality_score'].mean():.1f}/100")
print(f"  - Perfect scores (100): {(df['content_quality_score'] == 100).sum():,}")
print(f"  - Good scores (80+): {(df['content_quality_score'] >= 80).sum():,}")
print(f"  - Needs work (<60): {(df['content_quality_score'] < 60).sum():,}")

# ==============================================================================
# 10. GENERATE REPORTS & SAVE
# ==============================================================================
print("\n" + "="*80)
print("[STEP 10] GENERATING REPORTS & SAVING")
print("="*80)

# Save cleaned dataset
df.to_csv('../data/shopify_clean_step4.csv', index=False)
print(f"\nâœ… Saved cleaned dataset to '../data/shopify_clean_step4.csv'")

# Create detailed report
report = []
report.append("="*80)
report.append("TEXT CLEANING & SEO GENERATION REPORT - DAY 4")
report.append("="*80)
report.append(f"\nTotal Products: {len(df):,}")
report.append(f"\n{'='*80}")
report.append("\nIMPROVEMENTS:")
report.append(f"\nSEO Titles: {seo_before:,} â†’ {seo_after:,} (+{seo_after - seo_before:,})")
report.append(f"SEO Descriptions: {desc_before:,} â†’ {desc_after:,} (+{desc_after - desc_before:,})")
report.append(f"Tagged Products: {len(df) - tags_before:,} â†’ {df['has_tags'].sum():,}")
report.append(f"\n{'='*80}")
report.append("\nCONTENT QUALITY:")
report.append(f"  - Average quality score: {df['content_quality_score'].mean():.1f}/100")
report.append(f"  - Products with perfect score (100): {(df['content_quality_score'] == 100).sum():,}")
report.append(f"  - Products needing improvement (<60): {(df['content_quality_score'] < 60).sum():,}")
report.append(f"\n{'='*80}")
report.append("\nSAMPLE SEO TITLES:")
for i, title in enumerate(df['SEO Title'].head(10), 1):
    report.append(f"  {i}. {title}")
report.append(f"\n{'='*80}")
report.append("\nNEW COLUMNS ADDED:")
report.append("  - title_length: Character count of titles")
report.append("  - title_truncated: SEO-optimized versions")
report.append("  - tag_count: Number of tags per product")
report.append("  - description_length: Description character count")
report.append("  - has_seo_title: Quality flag")
report.append("  - has_seo_description: Quality flag")
report.append("  - has_tags: Quality flag")
report.append("  - has_description: Quality flag")
report.append("  - content_quality_score: Overall content score (0-100)")
report.append(f"\n{'='*80}")

report_text = "\n".join(report)

with open('text_cleaning_report.txt', 'w', encoding='utf-8') as f:
    f.write(report_text)

print(f"âœ… Saved detailed report to 'text_cleaning_report.txt'")

# Final summary
print("\n" + "="*80)
print("DAY 4 COMPLETE! ðŸŽ‰")
print("="*80)
print(f"\nâœ… Generated {seo_after - seo_before:,} SEO titles")
print(f"âœ… Generated {desc_after - desc_before:,} SEO descriptions")
print(f"âœ… Cleaned vendors, categories, tags, and titles")
print(f"âœ… Added {len([c for c in df.columns if c not in pd.read_csv('../data/shopify_clean_step3.csv').columns])} new quality columns")
print(f"âœ… Average content quality score: {df['content_quality_score'].mean():.1f}/100")

print("\nðŸ“Š BEFORE vs AFTER:")
print(f"  SEO Coverage: 0% â†’ 100%")
print(f"  Data Quality: Significantly Improved")
print(f"  Ready for: Analytics, SEO optimization, and Day 5!")

print("\n" + "="*80)